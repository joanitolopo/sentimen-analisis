{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang digunakan dapat didownload di: https://github.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia atau menggunakan ***git clone*** seperti contoh dibawah ini. Folder yang di _clone_ tersimpan ke dalam folder tempat file project ini disimpan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQhkN4DG2gXb",
    "outputId": "120f7340-a07e-4a82-b0a2-7b7de9bc2337"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/rizalespe/Dataset-Sentimen-Analisis-Bahasa-Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQLN-l93iF2B"
   },
   "source": [
    "## Install Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirement Package**:\n",
    "\n",
    "```\n",
    "1. nltk : https://www.nltk.org/\n",
    "2. Sastrawi: https://github.com/sastrawi/sastrawi\n",
    "3. numpy: https://numpy.org/\n",
    "4. pandas: https://pandas.pydata.org/\n",
    "5. sklearn: https://scikit-learn.org/stable/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZMhPthAicoE"
   },
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Sastrawi\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "uq4zAXNPih6-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from string import punctuation\n",
    "import os\n",
    "import json\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from jcopml.pipeline import num_pipe, cat_pipe\n",
    "from jcopml.utils import save_model, load_model\n",
    "from jcopml.plot import plot_missing_value\n",
    "from jcopml.feature_importance import mean_score_decrease\n",
    "\n",
    "factory_stopwords = StopWordRemoverFactory()\n",
    "sw_indo = factory_stopwords.get_stop_words() + stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Instagram Comment Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Sentiment                             Instagram Comment Text\n",
       "0   1  negative   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...\n",
       "1   2  negative  Geblek lo tata...cowo bgt dibela2in balikan......\n",
       "2   3  negative  Kmrn termewek2 skr lengket lg duhhh kok labil ...\n",
       "3   4  negative  Intinya kalau kesel dengan ATT nya, gausah ke ...\n",
       "4   5  negative  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha..."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dataset_komentar_instagram_cyberbullying.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.Sentiment == 'negative'),'Sentiment']=0\n",
    "df.loc[(df.Sentiment == 'positive'),'Sentiment']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Instagram Comment Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;USERNAME&gt; TOLOL!! Gak ada hubungan nya kegug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Geblek lo tata...cowo bgt dibela2in balikan......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Kmrn termewek2 skr lengket lg duhhh kok labil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Intinya kalau kesel dengan ATT nya, gausah ke ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Sentiment                             Instagram Comment Text\n",
       "0   1          0   <USERNAME> TOLOL!! Gak ada hubungan nya kegug...\n",
       "1   2          0  Geblek lo tata...cowo bgt dibela2in balikan......\n",
       "2   3          0  Kmrn termewek2 skr lengket lg duhhh kok labil ...\n",
       "3   4          0  Intinya kalau kesel dengan ATT nya, gausah ke ...\n",
       "4   5          0  hadewwwww permpuan itu lg!!!!sakit jiwa,knp ha..."
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320,), (80,), (320,), (80,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"Instagram Comment Text\"]\n",
    "y = df.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from jcopml.tuning import random_search_params as rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   44.0s finished\n",
      "C:\\Users\\Asus\\miniconda3\\envs\\jcop_usl\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo__C': 98.77700294007921, 'algo__gamma': 0.01879466824163846}\n",
      "1.0 0.8187562452242404 0.875\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('prep', TfidfVectorizer(tokenizer=word_tokenize, stop_words=sw_indo, ngram_range=(1,3))),\n",
    "    ('algo', SVC(max_iter=500))\n",
    "])\n",
    "\n",
    "model = RandomizedSearchCV(pipeline, rsp.svm_params, cv=3, n_iter=50, n_jobs=-1, verbose=1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "print(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anyiennnnggg.. suaranya ancur banget, lebih merdu tukang gorengan']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [X_train[9].lower()]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is pickled as model/model_best_svm.pkl\n"
     ]
    }
   ],
   "source": [
    "# save_model(model, \"model_best_svm.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X_test.tolist(), np.array([y_test.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth Predicted Tweet\n",
      "0\t1.00\tb'jelek,lecek,bantet ??????'\n",
      "0\t1.00\tb'semoga pelakor2 kena karma dan semoga dapat karma yg meninggalkan istrinya yg bwrjuang dg dia dr nol tp setelah sukses selingkuh dan sok jd penguasa ke istri ya..'\n",
      "1\t0.00\tb'kasian anaknya,, jgn sampek anaknya rusak jugak kek emaknya yaa'\n",
      "1\t0.00\tb'beruntungnya bella.. orang2 jadi fokus ama komen lakinya. coba kalo ngga, pasti model bajunya yang diceramahin ama netizen ??'\n",
      "0\t1.00\tb'yg gk becus tuh loh jedun...hidup nya cuma bisanya ngerusak kbhgiaan org lain .mau hidup serba mewah tp g mau krja mlh morotin laki org..karma psti akn mnghampirimu????????'\n",
      "0\t1.00\tb'geblek lo tata...cowo bgt dibela2in balikan...hadeww...ntar ditinggal lg nyalahin tuh cowo...padahal kitenya yg oon.'\n",
      "1\t0.00\tb'yg komen kenapa si mbak ini ga sedih malah ketawa2.. ya iyalah klo kita dah disakiti sm pasangan smpe berlarut2 ngapain juga sih kita sedih ampe depresi segala.. serahin sm allah aja..bawa happy aja mski sakit.. lagian si mba senyum2 di wajahnya tp hatinya mana tau kan... senyumannya bs jd buat menetralisir kondisi hatinya yg lg terpuruk... ada pepatah bilang ,, klo bahagia jgn trllu bahagia, klo sedih juga jgn trllu sedih... diimbangi aja biar ga gila ??????'\n",
      "0\t1.00\tb' <username> yutub apaan ya mba? aplikasi baru ya? sy taunya youtube. mba gak tau apa ya seseorg bs dpt penghasilan besar salah satunya dr youtube loh. mreka jg di bayar apalagi klo bnyk yg ntn video mreka. sekolah yg bener deh mba biar pinter. generasi muda'\n",
      "1\t0.00\tb'weewww bangga kali ak liatnya bang  <username> pake baju adat karo.... syip'\n",
      "1\t0.00\tb' <username> suami saya seumuran sama saya mba, malah tuaan saya beberapa bulan tapi alhamdulillah suami saya gak kekanak kanakan hehe'\n"
     ]
    }
   ],
   "source": [
    "print('Truth Predicted Tweet')\n",
    "for x, y in zip(X_pred_, y_pred_[-1]):\n",
    "    x = x.lower()\n",
    "    x = [x]\n",
    "    y_hat = model.predict(x)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(x).encode('ascii', 'ignore')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "GQLN-l93iF2B",
    "LZMhPthAicoE",
    "Nh5funiyhB5G",
    "hEOOD0DD0HN9",
    "3nODmHg3LWsh",
    "TLe8VnOkMB7o",
    "GvIYq4rbRti6",
    "MQQiPZRWQ0cL",
    "YnrdXH8VTg54"
   ],
   "name": "instagram-sentimen-analisi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:jcop_usl]",
   "language": "python",
   "name": "conda-env-jcop_usl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
